{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a4b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 7200 instances\n",
      "Validation set has 1800 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "device = torch.device('cuda')\n",
    "root_data_dir = 'dataset'\n",
    "class_name_to_label = {name: i for i, name in enumerate(os.listdir(root_data_dir))}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class RetailerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.img_paths, self.labels = zip(*[(os.path.join(root_dir, class_name, img_name), \n",
    "                                             class_name_to_label[class_name])\n",
    "                    for class_name in os.listdir(root_dir) \n",
    "                    for img_name in os.listdir(os.path.join(root_dir, class_name))\n",
    "                     ])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.img_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "retailer_set = RetailerDataset(root_data_dir, transform)\n",
    "training_set, validation_set = torch.utils.data.random_split(retailer_set, [int(len(retailer_set)*0.8), \n",
    "                                                                            int(len(retailer_set)*0.2)])\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True, num_workers=12)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=False, num_workers=12)\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab025433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = Net(num_classes=len(class_name_to_label), dropout=0.2)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af33448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    pbar = tqdm(enumerate(training_loader), total=len(training_loader))\n",
    "    for i, data in pbar:\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:\n",
    "            last_loss = running_loss / 5 # loss per batch\n",
    "            pbar.set_description('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "977eb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 1.3695806980133056: 100%|███| 113/113 [00:40<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 1.3695806980133056 valid 1.3540056943893433\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.9494886279106141: 100%|███| 113/113 [00:40<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.9494886279106141 valid 0.96705561876297\n",
      "EPOCH 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.6139802098274231: 100%|███| 113/113 [00:41<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6139802098274231 valid 0.8232817053794861\n",
      "EPOCH 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.6034131824970246: 100%|███| 113/113 [00:40<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6034131824970246 valid 0.7509422302246094\n",
      "EPOCH 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.5440339565277099: 100%|███| 113/113 [00:41<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5440339565277099 valid 0.5912086367607117\n",
      "EPOCH 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.4320400357246399: 100%|███| 113/113 [00:40<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.4320400357246399 valid 0.5947266221046448\n",
      "EPOCH 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.35255915522575376: 100%|██| 113/113 [00:41<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.35255915522575376 valid 0.5852555632591248\n",
      "EPOCH 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.30706451237201693: 100%|██| 113/113 [00:42<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.30706451237201693 valid 0.6075456142425537\n",
      "EPOCH 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.3238751232624054: 100%|███| 113/113 [00:41<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.3238751232624054 valid 0.6033531427383423\n",
      "EPOCH 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batch 110 loss: 0.3190418303012848: 100%|███| 113/113 [00:42<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.3190418303012848 valid 0.610502302646637\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 10\n",
    "model.to(device)\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        running_vloss = 0.0\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs.to(device))\n",
    "            vloss = loss_fn(voutputs, vlabels.to(device))\n",
    "            running_vloss += vloss.to('cpu')\n",
    "            \n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63ea08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(False)\n",
    "model.to(device)\n",
    "preds_labels = []\n",
    "gt_labels = []\n",
    "with torch.no_grad():\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs.to(device)).to('cpu')\n",
    "        _, preds = torch.max(voutputs, 1)\n",
    "        preds_labels.extend(preds.tolist())\n",
    "        gt_labels.extend(vlabels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43b2bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       115\n",
      "           1       0.36      0.57      0.44        76\n",
      "           2       0.67      0.56      0.61       135\n",
      "           3       0.94      0.92      0.93       119\n",
      "           4       0.90      0.86      0.88       120\n",
      "           5       0.78      0.59      0.67       177\n",
      "           6       0.97      0.87      0.92       151\n",
      "           7       0.65      0.93      0.76        90\n",
      "           8       0.45      0.58      0.51        93\n",
      "           9       0.86      0.83      0.84       111\n",
      "          10       0.81      0.71      0.76       143\n",
      "          11       0.93      0.96      0.95       114\n",
      "          12       0.72      0.73      0.72       113\n",
      "          13       0.92      0.99      0.95       104\n",
      "          14       0.89      0.82      0.85       139\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.78      0.78      0.78      1800\n",
      "weighted avg       0.80      0.78      0.78      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(preds_labels, gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464456ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
